{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8566d5f0-7a64-4afd-b3ae-1fe8bf61e57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/b10173209/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/b10173209/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/b10173209/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb\n",
    "import plotly.express as px\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4747e5ed-b1b0-4bcb-b4cc-2d4b5c5dea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/b10173209/test.file/train.txt'\n",
    "test_path = '/home/b10173209/test.file/test.txt'\n",
    "val_path = '/home/b10173209/test.file/val.txt'\n",
    "\n",
    "train_data = pd.read_csv(train_path, sep=';', names=['text', 'label'])\n",
    "test_data = pd.read_csv(test_path, sep=';', names=['text', 'label'])\n",
    "val_data = pd.read_csv(val_path, sep=';', names=['text', 'label'])\n",
    "\n",
    "# 確保標籤是數值型\n",
    "train_data['label'] = train_data['label'].astype('category').cat.codes\n",
    "test_data['label'] = test_data['label'].astype('category').cat.codes\n",
    "val_data['label'] = val_data['label'].astype('category').cat.codes\n",
    "\n",
    "# 合併訓練和驗證集\n",
    "data = pd.concat([train_data, val_data], ignore_index=True)\n",
    "train_labels = data['label']\n",
    "test_labels = test_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69c06622-af3e-4c91-8a35-739f7dbaa4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 StratifiedKFold 進行分層交叉驗證\n",
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# 定義參數網格\n",
    "learning_rate = 0.1\n",
    "max_depth = 9\n",
    "n_estimators = 300\n",
    "\n",
    "# Initialize results\n",
    "all_validation_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57d5f78a-c0ac-4a72-8b7e-ced4bfb5edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定義 Tokenizer\n",
    "def custom_tokenizer(text):\n",
    "    tokens = jieba.lcut(text)\n",
    "    return tokens\n",
    "\n",
    "# 定義文本預處理函數\n",
    "def preprocess_text(text):\n",
    "    processed_text = text.lower()  # 將文本轉為小寫\n",
    "    processed_text = re.sub(r'[^\\w\\s]', '', processed_text)  # 去除標點符號\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b009ac-4de5-49b2-810a-6315af0a4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=None)\n",
    "X_train_full = vectorizer.fit_transform(data['text'])\n",
    "X_test = vectorizer.transform(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fe27234-bf41-433d-a4c1-f02d555b0f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1/5\n",
      "Fold: 2/5\n",
      "Fold: 3/5\n",
      "Fold: 4/5\n",
      "Fold: 5/5\n",
      "Validation results saved to: /home/b10173209/test.file/X/integrate_validation_results_lr_0.1_md_9_ne_300.xlsx\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, val_index) in enumerate(skf.split(X_train_full, train_labels)):\n",
    "    print(f\"Fold: {fold + 1}/{num_folds}\")\n",
    "\n",
    "    # Split data\n",
    "    X_train_fold = X_train_full[train_index]\n",
    "    X_val_fold = X_train_full[val_index]\n",
    "    train_labels_fold = train_labels.iloc[train_index]\n",
    "    val_labels_fold = train_labels.iloc[val_index]\n",
    "\n",
    "\n",
    "    # Initialize and train XGBoost classifier\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_model.fit(X_train_fold, train_labels_fold)\n",
    "\n",
    "    # Validation predictions\n",
    "    predictions_val = xgb_model.predict(X_val_fold)\n",
    "\n",
    "    # Test predictions\n",
    "    predictions_test = xgb_model.predict(X_test)\n",
    "\n",
    "    # Store results\n",
    "    results = pd.DataFrame({\n",
    "        'Fold': [fold + 1] * len(val_index),\n",
    "        'id': val_index,  # Replace with actual IDs if available\n",
    "        'Labels': val_labels_fold.values,\n",
    "        'Predictions': predictions_val,\n",
    "        'Text': data['text'].iloc[val_index].values\n",
    "    })\n",
    "    all_validation_results.append(results)\n",
    "\n",
    "# Combine and save results\n",
    "all_validation_results_df = pd.concat(all_validation_results, ignore_index=True)\n",
    "excel_path = f'/home/b10173209/test.file/X/integrate_validation_results_lr_{learning_rate}_md_{max_depth}_ne_{n_estimators}.xlsx'\n",
    "all_validation_results_df.to_excel(excel_path, index=False)\n",
    "print(f\"Validation results saved to: {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0463327-e935-4f43-9cf2-e1207fbf9833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
